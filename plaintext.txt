English Transcript:
So the first of all you need to understand what is it text summarization a text summarization is the process of distilling the most important information from a source text the most of the time we do not have a time much time to go with the length lengthy text so by using this text summarization you can summarize whole text in a few particular sentences which will give you overall summary of overall text sentence why automatic text summarization is needed summarization reduces reading time and when researching document summarizes some reason the selection process easier automatic summarization improves the effectiveness of indexing and automatic summarizes and algorithms are less bash than the human sam rogers and first analyzed some reads are useful in christian answering systems as they provide personalized information and using automatic are a semi automatic summarization system enables commercial abstract services to increase the number of text documents they are able to process at resume a summarization is also available for a human resources department for a fasting screening and there are so many others there are so many other it wanted a advantages of text summarization how to text what are the types of the text summarization text summarization can be done based on the input types and then finally it can do a single document summarizations are a multi document. I mean the the the summarization can be based on a single documents or multiple documents and the text summarization can be based on the output types like extractive or obstructive okay extractive summarization means it will give you the summary by selecting few sentences from the overall the overall sentences in the obstructive it can finally make a total abstraction of overall text and then the based on the purposes text summarization can be done like the generic summarizations domain-specific summarizations our query based summarization the question is how to do the text summarization it is the text cleaning you need to do actually the first text cleaning then the sentence tokenization. And then we need to do word talk images and then what a frequency table and then finally overall summarization all right so let's say for example you have this text they are broadly two type of extractive summarization tasks depending on what the summarization program focus on so i have taken this text a piece of text from wikipedia article which is basically based on the text summarization so this is quite larger other document but there are three line this this and these three lines there And we can print the tokens here so let's go ahead and print these tokens now the one thing you should notice here is that punctuation x' and the stop words are also part of original token see here are two of two so on what is the these are stop words and you see here a round bracket and dart and apart from this the full stop there is your closing round bracket and there is comma so on these a part of the token now our task is also removed these stop words as well as punctuation so let's go ahead and see what are the functions our label which we can remove so these are the functions but the one thing you should notice there there is no new line so we need to add new line in the punctuation as well so we have also added a new line here all right so let's go ahead and build the word frequency first as in this step i told you that we need to do the text cleaning so the text cleaning is just a part of removing stop words and punctuation and then were the tokenization and then quite a frequency table so we need to calculate each of these words how many times has occurred in this text and then we based on those frequency we need we will identify. That the most important sentence okay so here we have part underscore frequency this is the dictionary which we are going to make here word frequencies for word in doc if word dot text dot lower okay not in stop words and similarly if word dot text thought lower not in punctuation okay and then if were dot what if it were talk text not in word frequency h dot pitch then were frequency h and there we have world dot text equal to one ills word frequencies and then word dot text is equal to plus and equal to one so this is actually how it is happening if any key is is being introduced the first time the word of that occurrence will be equal to one but if after the first time it is being introduced for Yeah just paste it here and the only difference is that we are going to add the previous sentence score in this one so that we can achieve by just putting here plus sign all right so let's go ahead and run this and let's go ahead and get the sentences score so here we have got the sentence score for each of these sentences now you see a sentences score is presented for each of the sentence now our task is an hour now our task is to get have the 30 percent of sentence with maximum score that we can achieve by using this package and largest that we can get with the hip queue from here queue import and largest now let's go ahead and let here select length is equal to int off the total length of sentences score actual sentence tokens so it will tell us total length of sentences present and then multiplied by 03 that's mean select only the 30% of total sentences so the 30% of total sentences is 4 so we need to select for sentence which have a maximum frequency count here all right so let's go ahead and get here summary summary is equal to in largest and inside the and largest. So if word dot text and dot lower in word frequencies a dot key if it is present there then in that case what we are going to do here we are going to we we are going to add the values of actually you see there every word have normalized frequency comment there and we are going to add those normalized frequency count in each of these sentences and then with the maximum value we are going to select most important sentence so if sent not in sentence is course dot th in that case sentences score and then send is equal to what frequencies what dot text dot lower all right yes we need to copy just the same thing. Now let's go ahead and get the maximum of that frequency max frequency that is max off where the frequencies dot cage perhaps that values not the cage so here we have max frequency that is 11 now what we are going to do we are going to divide or each of these values by a label so that a normalized frequency can be achieved so 11/11 is one and that one is maximum normalized frequency So this is full original text and out of these original text we have got the summary by our model now let's go ahead and compare the length of original text and the summary so the length of original text is 1869 and the length of summary after summarization is 605 now you can see it is almost 230 percents of her original sentence original length of text all right perfect. You press shift in the double-time it asks about and and then iterate able and then the cage so n here we have select length and then finally we have sentences score and for the cage that's the key for the key we have sentence is coarse so dot yet alright so get the keys from sentences scored out case perhaps alright so here we have summary now you see here so these three sentences has been assorted from these full list of sentences so these three sentences represents the summary of the sentences and the summary of her text. So let's go ahead and print it now we print it so this is summary and we have already seen the original text original text is we can get from the text so this was original text actually.